{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71c97f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf12436",
   "metadata": {},
   "source": [
    "# Jatin's version \n",
    "## Ctrl+A and uncomment and comment next code block to run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71e3cc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "class Decision_Tree:\n",
    "    def __init__(self, max_depth=10, min_samples_split=5):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "\n",
    "    \n",
    "    # -------------------------\n",
    "    # Entropy\n",
    "    # -------------------------\n",
    "    def entropy(self, y):\n",
    "        counts = np.bincount(y.ravel())\n",
    "        probs = counts[counts > 0] / len(y)\n",
    "        return -np.sum(probs * np.log2(probs))\n",
    "\n",
    "    # -------------------------\n",
    "    # Information Gain\n",
    "    # -------------------------\n",
    "    def information_gain(self, X_column, y, threshold):\n",
    "        parent_entropy = self.entropy(y)\n",
    "\n",
    "        left_idx = X_column < threshold\n",
    "        right_idx = ~left_idx\n",
    "\n",
    "        if left_idx.sum() == 0 or right_idx.sum() == 0:\n",
    "            return 0\n",
    "\n",
    "        n = len(y)\n",
    "        n_left = left_idx.sum()\n",
    "        n_right = right_idx.sum()\n",
    "\n",
    "        left_entropy = self.entropy(y[left_idx])\n",
    "        right_entropy = self.entropy(y[right_idx])\n",
    "\n",
    "        child_entropy = (n_left/n) * left_entropy + (n_right/n) * right_entropy\n",
    "\n",
    "        return parent_entropy - child_entropy\n",
    "\n",
    "    # -------------------------\n",
    "    # Best Split\n",
    "    # -------------------------\n",
    "    def best_split(self, X, y, indices):\n",
    "        best_gain = -1\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "\n",
    "        X_sub = X[indices]\n",
    "        y_sub = y[indices]\n",
    "\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        for feature in range(n_features):\n",
    "            values = X_sub[:, feature]\n",
    "            thresholds = np.unique(values)\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                gain = self.information_gain(values, y_sub, threshold)\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        return best_feature, best_threshold, best_gain\n",
    "    \n",
    "\n",
    "    # -------------------------\n",
    "    # Tree Builder\n",
    "    # -------------------------\n",
    "    def buildTree(self, X, y, indices, depth):\n",
    "        y_sub = y[indices]\n",
    "\n",
    "        if depth >= self.max_depth or len(indices) < self.min_samples_split or len(np.unique(y_sub)) == 1:\n",
    "            return Node(value=self.majority_vote(y_sub))\n",
    "\n",
    "        feature, threshold, gain = self.best_split(X, y, indices)\n",
    "\n",
    "        if gain <= 0:\n",
    "            return Node(value=self.majority_vote(y_sub))\n",
    "\n",
    "        X_sub = X[indices]\n",
    "\n",
    "        left_idx = indices[X_sub[:, feature] < threshold]\n",
    "        right_idx = indices[X_sub[:, feature] >= threshold]\n",
    "\n",
    "        left_child = self.buildTree(X, y, left_idx, depth+1)\n",
    "        right_child = self.buildTree(X, y, right_idx, depth+1)\n",
    "\n",
    "        return Node(feature=feature, threshold=threshold,\n",
    "                    left=left_child, right=right_child)\n",
    "\n",
    "    # -------------------------\n",
    "    # Utility\n",
    "    # -------------------------\n",
    "    def majority_vote(self, y):\n",
    "        values, counts = np.unique(y, return_counts=True)\n",
    "        return values[np.argmax(counts)]\n",
    "\n",
    "    # -------------------------\n",
    "    # Fit\n",
    "    # -------------------------\n",
    "    def fit(self, X, y):\n",
    "        indices = np.arange(len(X))\n",
    "        self.root = self.buildTree(X, y, indices, 0)\n",
    "\n",
    "    # -------------------------\n",
    "    # Predict\n",
    "    # -------------------------\n",
    "    def predict_one(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        if x[node.feature] < node.threshold:\n",
    "            return self.predict_one(x, node.left)\n",
    "        else:\n",
    "            return self.predict_one(x, node.right)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.predict_one(x, self.root) for x in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5880487b",
   "metadata": {},
   "source": [
    "## Ai correction because jatin had 100% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fe3362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# class Node:\n",
    "#     def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
    "#         self.feature = feature\n",
    "#         self.threshold = threshold\n",
    "#         self.left = left\n",
    "#         self.right = right\n",
    "#         self.value = value\n",
    "\n",
    "\n",
    "# class Decision_Tree:\n",
    "#     def __init__(self, max_depth=20, min_samples_split=2, min_samples_leaf=1, max_features=\"sqrt\"):\n",
    "#         self.max_depth = max_depth\n",
    "#         self.min_samples_split = min_samples_split\n",
    "#         self.min_samples_leaf = min_samples_leaf\n",
    "#         self.max_features = max_features\n",
    "#         self.root = None\n",
    "\n",
    "#     # ---------------------------------------------------------\n",
    "#     # Entropy (robust version: handles non-contiguous classes)\n",
    "#     # ---------------------------------------------------------\n",
    "#     def entropy(self, y):\n",
    "#         labels, counts = np.unique(y, return_counts=True)\n",
    "#         probs = counts / len(y)\n",
    "#         return -np.sum(probs * np.log2(probs))\n",
    "\n",
    "#     # ---------------------------------------------------------\n",
    "#     # Information Gain\n",
    "#     # ---------------------------------------------------------\n",
    "#     def information_gain(self, X_column, y, threshold):\n",
    "#         parent_entropy = self.entropy(y)\n",
    "\n",
    "#         left_mask = X_column < threshold\n",
    "#         right_mask = ~left_mask\n",
    "\n",
    "#         if left_mask.sum() == 0 or right_mask.sum() == 0:\n",
    "#             return 0\n",
    "\n",
    "#         n = len(y)\n",
    "#         n_left = left_mask.sum()\n",
    "#         n_right = right_mask.sum()\n",
    "\n",
    "#         left_entropy = self.entropy(y[left_mask])\n",
    "#         right_entropy = self.entropy(y[right_mask])\n",
    "\n",
    "#         child_entropy = (n_left / n) * left_entropy + (n_right / n) * right_entropy\n",
    "\n",
    "#         return parent_entropy - child_entropy\n",
    "\n",
    "#     # ---------------------------------------------------------\n",
    "#     # Select feature subset (random)\n",
    "#     # ---------------------------------------------------------\n",
    "#     def select_features(self, n_features):\n",
    "#         if self.max_features == \"sqrt\":\n",
    "#             k = int(np.sqrt(n_features))\n",
    "#         elif isinstance(self.max_features, int):\n",
    "#             k = min(self.max_features, n_features)\n",
    "#         else:\n",
    "#             k = n_features\n",
    "\n",
    "#         return np.random.choice(n_features, k, replace=False)\n",
    "\n",
    "#     # ---------------------------------------------------------\n",
    "#     # Best Split (fixed threshold logic + random features)\n",
    "#     # ---------------------------------------------------------\n",
    "#     def best_split(self, X, y, indices):\n",
    "#         X_sub = X[indices]\n",
    "#         y_sub = y[indices]\n",
    "\n",
    "#         n_features = X_sub.shape[1]\n",
    "#         feature_candidates = self.select_features(n_features)\n",
    "\n",
    "#         best_gain = -1\n",
    "#         best_feature = None\n",
    "#         best_threshold = None\n",
    "\n",
    "#         for feature in feature_candidates:\n",
    "#             values = X_sub[:, feature]\n",
    "#             uniq = np.unique(values)\n",
    "\n",
    "#             if len(uniq) <= 1:\n",
    "#                 continue\n",
    "\n",
    "#             thresholds = (uniq[:-1] + uniq[1:]) / 2\n",
    "\n",
    "#             for threshold in thresholds:\n",
    "#                 gain = self.information_gain(values, y_sub, threshold)\n",
    "#                 if gain > best_gain:\n",
    "#                     best_gain = gain\n",
    "#                     best_feature = feature\n",
    "#                     best_threshold = threshold\n",
    "\n",
    "#         return best_feature, best_threshold, best_gain\n",
    "\n",
    "#     # ---------------------------------------------------------\n",
    "#     # Tree Builder\n",
    "#     # ---------------------------------------------------------\n",
    "#     def buildTree(self, X, y, indices, depth):\n",
    "#         y_sub = y[indices]\n",
    "\n",
    "#         # stopping conditions\n",
    "#         if (\n",
    "#             depth >= self.max_depth or\n",
    "#             len(indices) < self.min_samples_split or\n",
    "#             len(indices) <= self.min_samples_leaf or\n",
    "#             len(np.unique(y_sub)) == 1\n",
    "#         ):\n",
    "#             return Node(value=self.majority_vote(y_sub))\n",
    "\n",
    "#         feature, threshold, gain = self.best_split(X, y, indices)\n",
    "\n",
    "#         # no useful split\n",
    "#         if feature is None or gain <= 1e-9:\n",
    "#             return Node(value=self.majority_vote(y_sub))\n",
    "\n",
    "#         X_sub = X[indices]\n",
    "#         mask = X_sub[:, feature] < threshold\n",
    "\n",
    "#         left_idx = indices[mask]\n",
    "#         right_idx = indices[~mask]\n",
    "\n",
    "#         left_child = self.buildTree(X, y, left_idx, depth + 1)\n",
    "#         right_child = self.buildTree(X, y, right_idx, depth + 1)\n",
    "\n",
    "#         return Node(feature=feature, threshold=threshold,\n",
    "#                     left=left_child, right=right_child)\n",
    "\n",
    "#     # ---------------------------------------------------------\n",
    "#     # Majority Voting\n",
    "#     # ---------------------------------------------------------\n",
    "#     def majority_vote(self, y):\n",
    "#         values, counts = np.unique(y, return_counts=True)\n",
    "#         return values[np.argmax(counts)]\n",
    "\n",
    "#     # ---------------------------------------------------------\n",
    "#     # Fit\n",
    "#     # ---------------------------------------------------------\n",
    "#     def fit(self, X, y):\n",
    "#         indices = np.arange(len(X))\n",
    "#         self.root = self.buildTree(X, y, indices, 0)\n",
    "\n",
    "#     # ---------------------------------------------------------\n",
    "#     # Predict\n",
    "#     # ---------------------------------------------------------\n",
    "#     def predict_one(self, x, node):\n",
    "#         if node.value is not None:\n",
    "#             return node.value\n",
    "#         if x[node.feature] < node.threshold:\n",
    "#             return self.predict_one(x, node.left)\n",
    "#         else:\n",
    "#             return self.predict_one(x, node.right)\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         return np.array([self.predict_one(x, self.root) for x in X])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31619a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500000 entries, 0 to 499999\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   Age            500000 non-null  int64  \n",
      " 1   Gender         500000 non-null  int64  \n",
      " 2   BMI            500000 non-null  float64\n",
      " 3   Smoking        500000 non-null  int64  \n",
      " 4   Alcohol        500000 non-null  int64  \n",
      " 5   ExerciseHours  500000 non-null  float64\n",
      " 6   SleepHours     500000 non-null  float64\n",
      " 7   DietScore      500000 non-null  int64  \n",
      " 8   BloodPressure  500000 non-null  int64  \n",
      " 9   BloodSugar     500000 non-null  int64  \n",
      " 10  Cholesterol    500000 non-null  int64  \n",
      " 11  DiseaseRisk    500000 non-null  int64  \n",
      "dtypes: float64(3), int64(9)\n",
      "memory usage: 45.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/synthetic_lifestyle_disease_transformed.csv\")\n",
    "df = df.drop([\"Unnamed: 0\"], axis=1)\n",
    "print(df.info())\n",
    "target = df.iloc[:,-1:]\n",
    "features = df.iloc[:,:-1]\n",
    "\n",
    "x_train = features[:300000]\n",
    "y_train = target[:300000]\n",
    "x_test = features[300000:]\n",
    "y_test = target[300000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "026c8963",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Decision_Tree(max_depth=10)\n",
    "model.fit(x_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "492f6822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000,)\n",
      "confusion : [[140318      0]\n",
      " [     0  59682]]\n",
      "R2 score: 1.0\n",
      "Accuracy score: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JATIN\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test.values)\n",
    "# mse = np.mean((y_pred - y_test.values) ** 2)\n",
    "print(y_pred.shape)\n",
    "# print(\"accuracy: \",(1 - mse) * 100)\n",
    "\n",
    "from sklearn.metrics import r2_score, accuracy_score,confusion_matrix\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "mat = confusion_matrix(y_pred,y_test)\n",
    "print(\"confusion :\", mat)\n",
    "print(\"R2 score:\", r2)\n",
    "print(\"Accuracy score:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2052011c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion : [[140318      0]\n",
      " [     0  59682]]\n",
      "accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(max_depth=15)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "mat = confusion_matrix(y_pred,y_test)\n",
    "print(\"confusion :\", mat)\n",
    "print(\"accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
